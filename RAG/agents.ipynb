{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: arxiv in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (2.1.0)\n",
      "Requirement already satisfied: feedparser==6.0.10 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from arxiv) (6.0.10)\n",
      "Requirement already satisfied: requests==2.31.0 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from arxiv) (2.31.0)\n",
      "Requirement already satisfied: sgmllib3k in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from feedparser==6.0.10->arxiv) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from requests==2.31.0->arxiv) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from requests==2.31.0->arxiv) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from requests==2.31.0->arxiv) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from requests==2.31.0->arxiv) (2024.2.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: wikipedia in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (1.4.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from wikipedia) (4.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from wikipedia) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from beautifulsoup4->wikipedia) (2.5)\n"
     ]
    }
   ],
   "source": [
    "#Part - 3\n",
    "\n",
    "#multisearch agent rag LLM application\n",
    "\n",
    "#We will learn about Tools, Toolkit, Agents\n",
    "\n",
    "!pip install arxiv\n",
    "!pip install wikipedia\n",
    "from langchain.tools import google_search\n",
    "\n",
    "#output = google_search(\"Tools for multisearch agent rag LLM application\")\n",
    "#print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "apiwraper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=200, lang='en')\n",
    "\n",
    "#print(apiwraper.query_and_summarize(\"Deep learning\"))\n",
    "tool_wikipedia = WikipediaQueryRun(api_wrapper=apiwraper)\n",
    "tool_wikipedia.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-proj-sDfBYiD0PHkbELY1n7OTT3BlbkFJjZdHRcNQXF3sz6JF8Qld\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x13c4bea30>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../.env.py')\n",
    "print(os.getenv('OPENAI_API_KEY'))\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "\n",
    "loader = WebBaseLoader('https://docs.smith.langchain.com/')\n",
    "docs = loader.load()\n",
    "\n",
    "documents = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100).split_documents(docs)\n",
    "vectordb = FAISS.from_documents(documents, OpenAIEmbeddings())\n",
    "retriever1 = vectordb.as_retriever()\n",
    "\n",
    "retriever1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langsmith_search'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "documentprompt = \"\"\n",
    "retriever_tool = create_retriever_tool(retriever1, \"langsmith_search\", \"Search about langsmith as a framework, for any questions about langsmith capabilities or how to use langsmith\")\n",
    "retriever_tool.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "\n",
    "arxivwrapper = ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "tool_arxiv = ArxivQueryRun(api_wrapper=arxivwrapper)\n",
    "tool_arxiv.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='langsmith_search', description='Search about langsmith as a framework, for any questions about langsmith capabilities or how to use langsmith', args_schema=<class 'langchain_core.tools.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x1081571f0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x13c4bea30>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x1081573a0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x13c4bea30>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n')),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=200, arxiv_result=<class 'arxiv.Result'>)),\n",
       " WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [retriever_tool, tool_arxiv, tool_wikipedia]\n",
    "tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain_openai in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (0.1.6)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.46 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from langchain_openai) (0.1.50)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.24.0 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from langchain_openai) (1.25.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from langchain_openai) (0.6.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (0.1.54)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (2.7.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (8.2.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.11.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2024.4.28)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain_openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain_openai) (1.2.1)\n",
      "Requirement already satisfied: certifi in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.46->langchain_openai) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.46->langchain_openai) (3.10.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.46->langchain_openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.46->langchain_openai) (2.18.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (2.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_openai\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%pip install langchainhub\n",
    "#Function Agents from hub for prompts\n",
    "\n",
    "from langchain import hub\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agents\n",
    "\n",
    "from langchain.agents import create_openai_tools_agent\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x12801a340>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x13c4bef40>, temperature=0.6, openai_api_key='sk-proj-sDfBYiD0PHkbELY1n7OTT3BlbkFJjZdHRcNQXF3sz6JF8Qld', openai_proxy=''), kwargs={'tools': [{'type': 'function', 'function': {'name': 'langsmith_search', 'description': 'Search about langsmith as a framework, for any questions about langsmith capabilities or how to use langsmith', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'__arg1': {'title': '__arg1', 'type': 'string'}}, 'required': ['__arg1'], 'type': 'object'}}}]})\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[Tool(name='langsmith_search', description='Search about langsmith as a framework, for any questions about langsmith capabilities or how to use langsmith', args_schema=<class 'langchain_core.tools.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x1081571f0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x13c4bea30>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x1081573a0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x13c4bea30>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n')), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=200, arxiv_result=<class 'arxiv.Result'>)), WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/Users/ashishbajpai/Library/Python/3.9/lib/python/site-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Agent Executor\n",
    "\n",
    "from langchain.agents import AgentExecutor\n",
    "agentexecutor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agentexecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'langsmith'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mGet started with LangSmith | 🦜️🛠️ LangSmith\n",
      "\n",
      "Skip to main contentLangSmith API DocsSearchGo to AppQuick startTutorialsHow-to guidesConceptsReferencePricingSelf-hostingQuick startOn this pageGet started with LangSmithLangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!1. Install LangSmith​PythonTypeScriptpip install -U langsmithyarn add langchain\n",
      "\n",
      "evaluation in the how-to guides.Was this page helpful?NextTutorials1. Install LangSmith2. Create an API key3. Set up your environment4. Log your first trace5. Run your first evaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.\n",
      "\n",
      "works on its own!1. Install LangSmith​PythonTypeScriptpip install -U langsmithyarn add langchain langsmith2. Create an API key​To create an API key head to the Settings page. Then click Create API Key.3. Set up your environment​Shellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key># The below examples use the OpenAI API, though it's not necessary in generalexport OPENAI_API_KEY=<your-openai-api-key>4. Log your first trace​We provide multiple ways to log traces to\u001b[0m\u001b[32;1m\u001b[1;3mLangSmith is a platform for building production-grade LLM (Large Language Model) applications. It allows you to closely monitor and evaluate your application, enabling you to ship quickly and with confidence. LangSmith works independently and does not require the use of LangChain. \n",
      "\n",
      "To get started with LangSmith, you can follow these steps:\n",
      "1. Install LangSmith using Python or TypeScript:\n",
      "   - Python: `pip install -U langsmith`\n",
      "   - TypeScript: `yarn add langchain langsmith`\n",
      "\n",
      "2. Create an API key by heading to the Settings page and clicking on Create API Key.\n",
      "\n",
      "3. Set up your environment by exporting the necessary variables:\n",
      "   ```\n",
      "   export LANGCHAIN_TRACING_V2=true\n",
      "   export LANGCHAIN_API_KEY=<your-api-key>\n",
      "   export OPENAI_API_KEY=<your-openai-api-key>  # Example using the OpenAI API key\n",
      "   ```\n",
      "\n",
      "4. Log your first trace using the provided methods.\n",
      "\n",
      "LangSmith provides detailed documentation, tutorials, how-to guides, and a community for support. You can find more information on the LangSmith homepage, blog, and GitHub repository.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about langsmith',\n",
       " 'output': 'LangSmith is a platform for building production-grade LLM (Large Language Model) applications. It allows you to closely monitor and evaluate your application, enabling you to ship quickly and with confidence. LangSmith works independently and does not require the use of LangChain. \\n\\nTo get started with LangSmith, you can follow these steps:\\n1. Install LangSmith using Python or TypeScript:\\n   - Python: `pip install -U langsmith`\\n   - TypeScript: `yarn add langchain langsmith`\\n\\n2. Create an API key by heading to the Settings page and clicking on Create API Key.\\n\\n3. Set up your environment by exporting the necessary variables:\\n   ```\\n   export LANGCHAIN_TRACING_V2=true\\n   export LANGCHAIN_API_KEY=<your-api-key>\\n   export OPENAI_API_KEY=<your-openai-api-key>  # Example using the OpenAI API key\\n   ```\\n\\n4. Log your first trace using the provided methods.\\n\\nLangSmith provides detailed documentation, tutorials, how-to guides, and a community for support. You can find more information on the LangSmith homepage, blog, and GitHub repository.'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#invoke Agent executor\n",
    "agentexecutor.invoke({\"input\":\"Tell me about langsmith\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `deep learning`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mPage: Deep learning\n",
      "Summary: Deep learning is the subset of machine learning methods based on neural networks with representation learning. The adjective \"deep\" refers to the use of multiple layers in\u001b[0m\u001b[32;1m\u001b[1;3mDeep learning is a subset of machine learning methods that are based on neural networks with representation learning. The term \"deep\" in deep learning refers to the use of multiple layers in neural networks. If you would like more detailed information or have specific questions about deep learning, feel free to ask!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about deep learning',\n",
       " 'output': 'Deep learning is a subset of machine learning methods that are based on neural networks with representation learning. The term \"deep\" in deep learning refers to the use of multiple layers in neural networks. If you would like more detailed information or have specific questions about deep learning, feel free to ask!'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#invoke Agent executor\n",
    "agentexecutor.invoke({\"input\":\"Tell me about deep learning\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': 'Modeling pedestrian fundamental diagram based on Directional Statistics'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPublished: 2024-05-02\n",
      "Title: Modeling pedestrian fundamental diagram based on Directional Statistics\n",
      "Authors: Keiichiro Fujiya, Kota Nagasaki, Toru Seo\n",
      "Summary: Understanding pedestrian dynamics is cr\u001b[0m\u001b[32;1m\u001b[1;3mI found a paper titled \"Modeling pedestrian fundamental diagram based on Directional Statistics\" by Keiichiro Fujiya, Kota Nagasaki, and Toru Seo. The paper discusses understanding pedestrian dynamics. If you need more information or details from the paper, feel free to ask!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Modeling pedestrian fundamental diagram based on Directional Statistics',\n",
       " 'output': 'I found a paper titled \"Modeling pedestrian fundamental diagram based on Directional Statistics\" by Keiichiro Fujiya, Kota Nagasaki, and Toru Seo. The paper discusses understanding pedestrian dynamics. If you need more information or details from the paper, feel free to ask!'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#invoke Agent executor\n",
    "agentexecutor.invoke({\"input\":\"Modeling pedestrian fundamental diagram based on Directional Statistics\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
